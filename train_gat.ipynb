{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model import BotGAT\n",
    "from utils import accuracy, init_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "embedding_size = 32\n",
    "dropout = 0.1\n",
    "lr = 1e-2\n",
    "weight_decay = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re calculate Des Tensor\n",
    "path = \"/Dataset/\"\n",
    "des_tensor = torch.load(path + \"filtered_des_tensor.pt\").t().to(device)\n",
    "\n",
    "num_prop = torch.load(path + \"filtered_num_properties_tensor.pt\").t().to(device)\n",
    "category_prop = torch.load(path + \"filtered_cat_properties_tensor.pt\").t().to(device)\n",
    "labels = torch.load(path + \"filtered_label.pt\").t().to(device)\n",
    "\n",
    "tweets_tensor = torch.load(\"/Users/ketanjadhav/Documents/BotRGCN/processed_data/tweets_tensor.pt\").t().to(device)\n",
    "\n",
    "train_idx = torch.load(path + \"filtered_train_idx.pt\").to(device)\n",
    "val_idx = torch.load(path + \"filtered_val_idx.pt\").to(device)\n",
    "test_idx = torch.load(path + \"filtered_test_idx.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "follower_edge_index = torch.load(path + \"filtered_followers_edge_index.pt\").to(device)\n",
    "following_edge_index = torch.load(path + \"filtered_following_edge_index.pt\").to(device)\n",
    "interaction_edge_index = torch.load(path + \"filtered_interaction_edge_index.pt\").to(device)\n",
    "\n",
    "combined_edge_index = torch.load(path + \"filtered_edge_index.pt\").to(device)\n",
    "combined_edge_type = torch.load(path + \"filtered_edge_type.pt\").to(device)\n",
    "\n",
    "all_edge_index = torch.load(path + \"all_combined_edge_index.pt\").to(device)\n",
    "all_edge_type = torch.load(path + \"all_combined_edge_type.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BotGAT(\n",
       "  (linear_relu_des): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=10, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (linear_relu_num_prop): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=10, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (linear_relu_cat_prop): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=10, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (linear_relu_input): Sequential(\n",
       "    (0): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (linear_relu_output1): Sequential(\n",
       "    (0): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (linear_output2): Linear(in_features=30, out_features=2, bias=True)\n",
       "  (gat1): GATConv(30, 10, heads=3)\n",
       "  (gat2): GATConv(30, 30, heads=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gat_model=BotGAT(cat_prop_size=3,embedding_dimension=30).to(device)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(gat_model.parameters(),\n",
    "                    lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "gat_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gat(epoch, optimizer, train_edge_index):\n",
    "    gat_model.train()\n",
    "    output = gat_model(des_tensor, tweets_tensor, num_prop, category_prop, train_edge_index)\n",
    "    loss_train = loss(output[train_idx], labels[train_idx])\n",
    "    acc_train = accuracy(output[train_idx], labels[train_idx])\n",
    "    acc_val = accuracy(output[val_idx], labels[val_idx])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()))\n",
    "    \n",
    "    return acc_train, loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_gat(test_edge_index):\n",
    "    gat_model.eval()\n",
    "    output = gat_model(des_tensor, tweets_tensor, num_prop, category_prop, test_edge_index)\n",
    "    loss_test = loss(output[test_idx], labels[test_idx])\n",
    "    acc_test = accuracy(output[test_idx], labels[test_idx])\n",
    "    \n",
    "    output = output.max(1)[1].to('cpu').detach().numpy()\n",
    "    label = labels.to('cpu').detach().numpy()\n",
    "    \n",
    "    f1 = f1_score(label[test_idx], output[test_idx])\n",
    "    precision = precision_score(label[test_idx], output[test_idx])\n",
    "    recall = recall_score(label[test_idx], output[test_idx])\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(label[test_idx], output[test_idx], pos_label=1)\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    \n",
    "    print(\"Test set results:\",\n",
    "          \"test_loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"test_accuracy= {:.4f}\".format(acc_test.item()),\n",
    "          \"precision= {:.4f}\".format(precision.item()),\n",
    "          \"recall= {:.4f}\".format(recall.item()),\n",
    "          \"f1_score= {:.4f}\".format(f1.item()),\n",
    "          \"auc= {:.4f}\".format(auc_val.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOLLOWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508539\n",
      "Epoch: 0001 loss_train: 0.9720 acc_train: 0.4015 acc_val: 0.7006\n",
      "Epoch: 0002 loss_train: 0.8029 acc_train: 0.6653 acc_val: 0.1331\n",
      "Epoch: 0003 loss_train: 0.6505 acc_train: 0.6756 acc_val: 0.0310\n",
      "Epoch: 0004 loss_train: 0.6069 acc_train: 0.6891 acc_val: 0.0867\n",
      "Epoch: 0005 loss_train: 0.5870 acc_train: 0.6864 acc_val: 0.3201\n",
      "Epoch: 0006 loss_train: 0.5925 acc_train: 0.6719 acc_val: 0.4912\n",
      "Epoch: 0007 loss_train: 0.5670 acc_train: 0.7050 acc_val: 0.4007\n",
      "Epoch: 0008 loss_train: 0.5635 acc_train: 0.7224 acc_val: 0.2936\n",
      "Epoch: 0009 loss_train: 0.5555 acc_train: 0.7278 acc_val: 0.2934\n",
      "Epoch: 0010 loss_train: 0.5498 acc_train: 0.7303 acc_val: 0.3674\n",
      "Epoch: 0011 loss_train: 0.5420 acc_train: 0.7191 acc_val: 0.5009\n",
      "Epoch: 0012 loss_train: 0.5416 acc_train: 0.7100 acc_val: 0.5578\n",
      "Epoch: 0013 loss_train: 0.5238 acc_train: 0.7318 acc_val: 0.4358\n",
      "Epoch: 0014 loss_train: 0.5221 acc_train: 0.7390 acc_val: 0.3364\n",
      "Epoch: 0015 loss_train: 0.5227 acc_train: 0.7413 acc_val: 0.3194\n",
      "Epoch: 0016 loss_train: 0.5107 acc_train: 0.7433 acc_val: 0.3610\n",
      "Epoch: 0017 loss_train: 0.5110 acc_train: 0.7437 acc_val: 0.4328\n",
      "Epoch: 0018 loss_train: 0.5059 acc_train: 0.7471 acc_val: 0.4227\n",
      "Epoch: 0019 loss_train: 0.4989 acc_train: 0.7505 acc_val: 0.3637\n",
      "Epoch: 0020 loss_train: 0.4973 acc_train: 0.7527 acc_val: 0.3446\n",
      "Epoch: 0021 loss_train: 0.4926 acc_train: 0.7563 acc_val: 0.3664\n",
      "Epoch: 0022 loss_train: 0.4882 acc_train: 0.7599 acc_val: 0.4295\n",
      "Epoch: 0023 loss_train: 0.4867 acc_train: 0.7622 acc_val: 0.4706\n",
      "Epoch: 0024 loss_train: 0.4811 acc_train: 0.7650 acc_val: 0.4538\n",
      "Epoch: 0025 loss_train: 0.4773 acc_train: 0.7687 acc_val: 0.4157\n",
      "Epoch: 0026 loss_train: 0.4775 acc_train: 0.7705 acc_val: 0.4010\n",
      "Epoch: 0027 loss_train: 0.4723 acc_train: 0.7734 acc_val: 0.4236\n",
      "Epoch: 0028 loss_train: 0.4693 acc_train: 0.7754 acc_val: 0.4644\n",
      "Epoch: 0029 loss_train: 0.4753 acc_train: 0.7756 acc_val: 0.4842\n",
      "Epoch: 0030 loss_train: 0.4646 acc_train: 0.7784 acc_val: 0.4714\n",
      "Epoch: 0031 loss_train: 0.4616 acc_train: 0.7803 acc_val: 0.4384\n",
      "Epoch: 0032 loss_train: 0.4604 acc_train: 0.7805 acc_val: 0.4261\n",
      "Epoch: 0033 loss_train: 0.4582 acc_train: 0.7818 acc_val: 0.4416\n",
      "Epoch: 0034 loss_train: 0.4557 acc_train: 0.7824 acc_val: 0.4738\n",
      "Epoch: 0035 loss_train: 0.4543 acc_train: 0.7834 acc_val: 0.4875\n",
      "Epoch: 0036 loss_train: 0.4515 acc_train: 0.7854 acc_val: 0.4702\n",
      "Epoch: 0037 loss_train: 0.4507 acc_train: 0.7874 acc_val: 0.4478\n",
      "Epoch: 0038 loss_train: 0.4486 acc_train: 0.7891 acc_val: 0.4471\n",
      "Epoch: 0039 loss_train: 0.4454 acc_train: 0.7902 acc_val: 0.4663\n",
      "Epoch: 0040 loss_train: 0.4444 acc_train: 0.7909 acc_val: 0.4847\n",
      "Epoch: 0041 loss_train: 0.4419 acc_train: 0.7924 acc_val: 0.4777\n",
      "Epoch: 0042 loss_train: 0.4399 acc_train: 0.7943 acc_val: 0.4610\n",
      "Epoch: 0043 loss_train: 0.4382 acc_train: 0.7955 acc_val: 0.4557\n",
      "Epoch: 0044 loss_train: 0.4361 acc_train: 0.7972 acc_val: 0.4662\n",
      "Epoch: 0045 loss_train: 0.4338 acc_train: 0.7980 acc_val: 0.4825\n",
      "Epoch: 0046 loss_train: 0.4313 acc_train: 0.7992 acc_val: 0.4872\n",
      "Epoch: 0047 loss_train: 0.4295 acc_train: 0.8005 acc_val: 0.4757\n",
      "Epoch: 0048 loss_train: 0.4265 acc_train: 0.8018 acc_val: 0.4665\n",
      "Epoch: 0049 loss_train: 0.4246 acc_train: 0.8029 acc_val: 0.4753\n",
      "Epoch: 0050 loss_train: 0.4228 acc_train: 0.8039 acc_val: 0.4946\n",
      "Test set results: test_loss= 0.6632 test_accuracy= 0.6518 precision= 0.7059 recall= 0.5174 f1_score= 0.5971 auc= 0.6514\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "print(len(follower_edge_index[1]))\n",
    "for epoch in range(epochs):\n",
    "    train_gat(epoch, optimizer, follower_edge_index)\n",
    "    \n",
    "test_gat(follower_edge_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOLLOWING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.4775 acc_train: 0.7678 acc_val: 0.3695\n",
      "Epoch: 0002 loss_train: 0.4758 acc_train: 0.7689 acc_val: 0.3833\n",
      "Epoch: 0003 loss_train: 0.4748 acc_train: 0.7693 acc_val: 0.3887\n",
      "Epoch: 0004 loss_train: 0.4721 acc_train: 0.7708 acc_val: 0.3917\n",
      "Epoch: 0005 loss_train: 0.4700 acc_train: 0.7720 acc_val: 0.4015\n",
      "Epoch: 0006 loss_train: 0.4672 acc_train: 0.7731 acc_val: 0.4118\n",
      "Epoch: 0007 loss_train: 0.4651 acc_train: 0.7746 acc_val: 0.4234\n",
      "Epoch: 0008 loss_train: 0.4622 acc_train: 0.7747 acc_val: 0.4373\n",
      "Epoch: 0009 loss_train: 0.4594 acc_train: 0.7752 acc_val: 0.4373\n",
      "Epoch: 0010 loss_train: 0.4562 acc_train: 0.7751 acc_val: 0.4372\n",
      "Epoch: 0011 loss_train: 0.4532 acc_train: 0.7745 acc_val: 0.4521\n",
      "Epoch: 0012 loss_train: 0.4497 acc_train: 0.7760 acc_val: 0.4464\n",
      "Epoch: 0013 loss_train: 0.4465 acc_train: 0.7754 acc_val: 0.4564\n",
      "Epoch: 0014 loss_train: 0.4433 acc_train: 0.7770 acc_val: 0.4743\n",
      "Epoch: 0015 loss_train: 0.4395 acc_train: 0.7782 acc_val: 0.4627\n",
      "Epoch: 0016 loss_train: 0.4372 acc_train: 0.7806 acc_val: 0.5413\n",
      "Epoch: 0017 loss_train: 0.4355 acc_train: 0.7822 acc_val: 0.4609\n",
      "Epoch: 0018 loss_train: 0.4326 acc_train: 0.7881 acc_val: 0.6125\n",
      "Epoch: 0019 loss_train: 0.4314 acc_train: 0.7872 acc_val: 0.4763\n",
      "Epoch: 0020 loss_train: 0.4220 acc_train: 0.7992 acc_val: 0.6099\n",
      "Epoch: 0021 loss_train: 0.4178 acc_train: 0.8005 acc_val: 0.5855\n",
      "Epoch: 0022 loss_train: 0.4142 acc_train: 0.8031 acc_val: 0.5693\n",
      "Epoch: 0023 loss_train: 0.4117 acc_train: 0.8105 acc_val: 0.6582\n",
      "Epoch: 0024 loss_train: 0.4071 acc_train: 0.8104 acc_val: 0.5844\n",
      "Epoch: 0025 loss_train: 0.4003 acc_train: 0.8199 acc_val: 0.6439\n",
      "Epoch: 0026 loss_train: 0.3974 acc_train: 0.8227 acc_val: 0.6319\n",
      "Epoch: 0027 loss_train: 0.3950 acc_train: 0.8220 acc_val: 0.6107\n",
      "Epoch: 0028 loss_train: 0.3973 acc_train: 0.8270 acc_val: 0.7124\n",
      "Epoch: 0029 loss_train: 0.4019 acc_train: 0.8207 acc_val: 0.5589\n",
      "Epoch: 0030 loss_train: 0.4037 acc_train: 0.8246 acc_val: 0.7542\n",
      "Epoch: 0031 loss_train: 0.3879 acc_train: 0.8318 acc_val: 0.6032\n",
      "Epoch: 0032 loss_train: 0.3831 acc_train: 0.8349 acc_val: 0.6553\n",
      "Epoch: 0033 loss_train: 0.3914 acc_train: 0.8305 acc_val: 0.7681\n",
      "Epoch: 0034 loss_train: 0.3806 acc_train: 0.8386 acc_val: 0.6373\n",
      "Epoch: 0035 loss_train: 0.3751 acc_train: 0.8421 acc_val: 0.6608\n",
      "Epoch: 0036 loss_train: 0.3790 acc_train: 0.8411 acc_val: 0.7571\n",
      "Epoch: 0037 loss_train: 0.3711 acc_train: 0.8432 acc_val: 0.6845\n",
      "Epoch: 0038 loss_train: 0.3702 acc_train: 0.8450 acc_val: 0.6813\n",
      "Epoch: 0039 loss_train: 0.3739 acc_train: 0.8464 acc_val: 0.7610\n",
      "Epoch: 0040 loss_train: 0.3663 acc_train: 0.8471 acc_val: 0.6750\n",
      "Epoch: 0041 loss_train: 0.3621 acc_train: 0.8478 acc_val: 0.7021\n",
      "Epoch: 0042 loss_train: 0.3631 acc_train: 0.8498 acc_val: 0.7520\n",
      "Epoch: 0043 loss_train: 0.3582 acc_train: 0.8536 acc_val: 0.6889\n",
      "Epoch: 0044 loss_train: 0.3573 acc_train: 0.8550 acc_val: 0.6859\n",
      "Epoch: 0045 loss_train: 0.3564 acc_train: 0.8548 acc_val: 0.7391\n",
      "Epoch: 0046 loss_train: 0.3546 acc_train: 0.8543 acc_val: 0.7042\n",
      "Epoch: 0047 loss_train: 0.3524 acc_train: 0.8561 acc_val: 0.7122\n",
      "Epoch: 0048 loss_train: 0.3520 acc_train: 0.8592 acc_val: 0.7340\n",
      "Epoch: 0049 loss_train: 0.3506 acc_train: 0.8576 acc_val: 0.7006\n",
      "Epoch: 0050 loss_train: 0.3477 acc_train: 0.8595 acc_val: 0.7360\n",
      "Test set results: test_loss= 0.6289 test_accuracy= 0.7060 precision= 0.6825 recall= 0.7674 f1_score= 0.7225 auc= 0.7061\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "#(279886x4 and 6x10)\n",
    "for epoch in range(epochs):\n",
    "    train_gat(epoch, optimizer, following_edge_index)\n",
    "    \n",
    "test_gat(following_edge_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.2772 acc_train: 0.8868 acc_val: 0.7508\n",
      "Epoch: 0002 loss_train: 0.2760 acc_train: 0.8883 acc_val: 0.7338\n",
      "Epoch: 0003 loss_train: 0.2769 acc_train: 0.8861 acc_val: 0.7671\n",
      "Epoch: 0004 loss_train: 0.2760 acc_train: 0.8885 acc_val: 0.6883\n",
      "Epoch: 0005 loss_train: 0.2753 acc_train: 0.8875 acc_val: 0.7646\n",
      "Epoch: 0006 loss_train: 0.2687 acc_train: 0.8900 acc_val: 0.7263\n",
      "Epoch: 0007 loss_train: 0.2733 acc_train: 0.8882 acc_val: 0.6640\n",
      "Epoch: 0008 loss_train: 0.2677 acc_train: 0.8901 acc_val: 0.7426\n",
      "Epoch: 0009 loss_train: 0.2671 acc_train: 0.8904 acc_val: 0.7419\n",
      "Epoch: 0010 loss_train: 0.2657 acc_train: 0.8914 acc_val: 0.6842\n",
      "Epoch: 0011 loss_train: 0.2648 acc_train: 0.8915 acc_val: 0.6870\n",
      "Epoch: 0012 loss_train: 0.2632 acc_train: 0.8909 acc_val: 0.7485\n",
      "Epoch: 0013 loss_train: 0.2631 acc_train: 0.8909 acc_val: 0.7611\n",
      "Epoch: 0014 loss_train: 0.2610 acc_train: 0.8936 acc_val: 0.7183\n",
      "Epoch: 0015 loss_train: 0.2615 acc_train: 0.8935 acc_val: 0.7052\n",
      "Epoch: 0016 loss_train: 0.2596 acc_train: 0.8932 acc_val: 0.7442\n",
      "Epoch: 0017 loss_train: 0.2604 acc_train: 0.8921 acc_val: 0.7671\n",
      "Epoch: 0018 loss_train: 0.2583 acc_train: 0.8945 acc_val: 0.7388\n",
      "Epoch: 0019 loss_train: 0.2592 acc_train: 0.8948 acc_val: 0.7097\n",
      "Epoch: 0020 loss_train: 0.2569 acc_train: 0.8951 acc_val: 0.7318\n",
      "Epoch: 0021 loss_train: 0.2579 acc_train: 0.8941 acc_val: 0.7547\n",
      "Epoch: 0022 loss_train: 0.2558 acc_train: 0.8952 acc_val: 0.7377\n",
      "Epoch: 0023 loss_train: 0.2562 acc_train: 0.8955 acc_val: 0.7199\n",
      "Epoch: 0024 loss_train: 0.2553 acc_train: 0.8959 acc_val: 0.7344\n",
      "Epoch: 0025 loss_train: 0.2546 acc_train: 0.8958 acc_val: 0.7590\n",
      "Epoch: 0026 loss_train: 0.2537 acc_train: 0.8955 acc_val: 0.7484\n",
      "Epoch: 0027 loss_train: 0.2536 acc_train: 0.8967 acc_val: 0.7235\n",
      "Epoch: 0028 loss_train: 0.2524 acc_train: 0.8970 acc_val: 0.7301\n",
      "Epoch: 0029 loss_train: 0.2527 acc_train: 0.8966 acc_val: 0.7512\n",
      "Epoch: 0030 loss_train: 0.2519 acc_train: 0.8970 acc_val: 0.7508\n",
      "Epoch: 0031 loss_train: 0.2517 acc_train: 0.8975 acc_val: 0.7316\n",
      "Epoch: 0032 loss_train: 0.2511 acc_train: 0.8979 acc_val: 0.7360\n",
      "Epoch: 0033 loss_train: 0.2508 acc_train: 0.8976 acc_val: 0.7550\n",
      "Epoch: 0034 loss_train: 0.2499 acc_train: 0.8968 acc_val: 0.7558\n",
      "Epoch: 0035 loss_train: 0.2495 acc_train: 0.8983 acc_val: 0.7400\n",
      "Epoch: 0036 loss_train: 0.2497 acc_train: 0.8989 acc_val: 0.7383\n",
      "Epoch: 0037 loss_train: 0.2488 acc_train: 0.8983 acc_val: 0.7562\n",
      "Epoch: 0038 loss_train: 0.2488 acc_train: 0.8981 acc_val: 0.7611\n",
      "Epoch: 0039 loss_train: 0.2483 acc_train: 0.8986 acc_val: 0.7467\n",
      "Epoch: 0040 loss_train: 0.2482 acc_train: 0.8991 acc_val: 0.7435\n",
      "Epoch: 0041 loss_train: 0.2471 acc_train: 0.8990 acc_val: 0.7567\n",
      "Epoch: 0042 loss_train: 0.2470 acc_train: 0.8991 acc_val: 0.7572\n",
      "Epoch: 0043 loss_train: 0.2469 acc_train: 0.8996 acc_val: 0.7441\n",
      "Epoch: 0044 loss_train: 0.2463 acc_train: 0.8993 acc_val: 0.7448\n",
      "Epoch: 0045 loss_train: 0.2461 acc_train: 0.8999 acc_val: 0.7563\n",
      "Epoch: 0046 loss_train: 0.2460 acc_train: 0.8994 acc_val: 0.7548\n",
      "Epoch: 0047 loss_train: 0.2449 acc_train: 0.8998 acc_val: 0.7457\n",
      "Epoch: 0048 loss_train: 0.2447 acc_train: 0.9002 acc_val: 0.7505\n",
      "Epoch: 0049 loss_train: 0.2443 acc_train: 0.9006 acc_val: 0.7584\n",
      "Epoch: 0050 loss_train: 0.2445 acc_train: 0.9000 acc_val: 0.7498\n",
      "Test set results: test_loss= 0.5879 test_accuracy= 0.7383 precision= 0.7195 recall= 0.7790 f1_score= 0.7481 auc= 0.7384\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_gat(epoch, optimizer, interaction_edge_index)\n",
    "    \n",
    "test_gat(interaction_edge_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINED FOLLOWER_FOLLOWING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.4256 acc_train: 0.8210 acc_val: 0.5611\n",
      "Epoch: 0002 loss_train: 0.5415 acc_train: 0.7221 acc_val: 0.8891\n",
      "Epoch: 0003 loss_train: 0.4024 acc_train: 0.8322 acc_val: 0.5817\n",
      "Epoch: 0004 loss_train: 0.4811 acc_train: 0.7839 acc_val: 0.3616\n",
      "Epoch: 0005 loss_train: 0.4040 acc_train: 0.8198 acc_val: 0.7097\n",
      "Epoch: 0006 loss_train: 0.4658 acc_train: 0.7882 acc_val: 0.8478\n",
      "Epoch: 0007 loss_train: 0.4087 acc_train: 0.8273 acc_val: 0.7269\n",
      "Epoch: 0008 loss_train: 0.4120 acc_train: 0.8065 acc_val: 0.4635\n",
      "Epoch: 0009 loss_train: 0.4266 acc_train: 0.8042 acc_val: 0.4221\n",
      "Epoch: 0010 loss_train: 0.4008 acc_train: 0.8504 acc_val: 0.6126\n",
      "Epoch: 0011 loss_train: 0.4002 acc_train: 0.8488 acc_val: 0.7168\n",
      "Epoch: 0012 loss_train: 0.3929 acc_train: 0.8346 acc_val: 0.6697\n",
      "Epoch: 0013 loss_train: 0.4004 acc_train: 0.8282 acc_val: 0.6419\n",
      "Epoch: 0014 loss_train: 0.3757 acc_train: 0.8452 acc_val: 0.6923\n",
      "Epoch: 0015 loss_train: 0.3846 acc_train: 0.8461 acc_val: 0.6867\n",
      "Epoch: 0016 loss_train: 0.3847 acc_train: 0.8455 acc_val: 0.6643\n",
      "Epoch: 0017 loss_train: 0.3722 acc_train: 0.8487 acc_val: 0.6849\n",
      "Epoch: 0018 loss_train: 0.3703 acc_train: 0.8476 acc_val: 0.7255\n",
      "Epoch: 0019 loss_train: 0.3745 acc_train: 0.8474 acc_val: 0.7439\n",
      "Epoch: 0020 loss_train: 0.3659 acc_train: 0.8558 acc_val: 0.7227\n",
      "Epoch: 0021 loss_train: 0.3627 acc_train: 0.8609 acc_val: 0.6860\n",
      "Epoch: 0022 loss_train: 0.3641 acc_train: 0.8638 acc_val: 0.6934\n",
      "Epoch: 0023 loss_train: 0.3624 acc_train: 0.8612 acc_val: 0.6681\n",
      "Epoch: 0024 loss_train: 0.3546 acc_train: 0.8639 acc_val: 0.7284\n",
      "Epoch: 0025 loss_train: 0.3540 acc_train: 0.8605 acc_val: 0.7363\n",
      "Epoch: 0026 loss_train: 0.3527 acc_train: 0.8603 acc_val: 0.7238\n",
      "Epoch: 0027 loss_train: 0.3501 acc_train: 0.8641 acc_val: 0.7314\n",
      "Epoch: 0028 loss_train: 0.3519 acc_train: 0.8658 acc_val: 0.7211\n",
      "Epoch: 0029 loss_train: 0.3522 acc_train: 0.8642 acc_val: 0.6916\n",
      "Epoch: 0030 loss_train: 0.3459 acc_train: 0.8670 acc_val: 0.7349\n",
      "Epoch: 0031 loss_train: 0.3460 acc_train: 0.8662 acc_val: 0.7478\n",
      "Epoch: 0032 loss_train: 0.3450 acc_train: 0.8662 acc_val: 0.7291\n",
      "Epoch: 0033 loss_train: 0.3400 acc_train: 0.8702 acc_val: 0.7379\n",
      "Epoch: 0034 loss_train: 0.3407 acc_train: 0.8710 acc_val: 0.7205\n",
      "Epoch: 0035 loss_train: 0.3402 acc_train: 0.8725 acc_val: 0.7210\n",
      "Epoch: 0036 loss_train: 0.3377 acc_train: 0.8713 acc_val: 0.7353\n",
      "Epoch: 0037 loss_train: 0.3361 acc_train: 0.8715 acc_val: 0.7538\n",
      "Epoch: 0038 loss_train: 0.3369 acc_train: 0.8713 acc_val: 0.7554\n",
      "Epoch: 0039 loss_train: 0.3348 acc_train: 0.8738 acc_val: 0.7487\n",
      "Epoch: 0040 loss_train: 0.3344 acc_train: 0.8754 acc_val: 0.7466\n",
      "Epoch: 0041 loss_train: 0.3342 acc_train: 0.8734 acc_val: 0.7259\n",
      "Epoch: 0042 loss_train: 0.3354 acc_train: 0.8752 acc_val: 0.7721\n",
      "Epoch: 0043 loss_train: 0.3450 acc_train: 0.8683 acc_val: 0.7018\n",
      "Epoch: 0044 loss_train: 0.3470 acc_train: 0.8704 acc_val: 0.8011\n",
      "Epoch: 0045 loss_train: 0.3513 acc_train: 0.8662 acc_val: 0.6847\n",
      "Epoch: 0046 loss_train: 0.3331 acc_train: 0.8771 acc_val: 0.7755\n",
      "Epoch: 0047 loss_train: 0.3276 acc_train: 0.8788 acc_val: 0.7460\n",
      "Epoch: 0048 loss_train: 0.3349 acc_train: 0.8743 acc_val: 0.7078\n",
      "Epoch: 0049 loss_train: 0.3329 acc_train: 0.8777 acc_val: 0.7801\n",
      "Epoch: 0050 loss_train: 0.3280 acc_train: 0.8765 acc_val: 0.7358\n",
      "Test set results: test_loss= 0.6490 test_accuracy= 0.7095 precision= 0.6853 recall= 0.7720 f1_score= 0.7261 auc= 0.7096\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_gat(epoch, optimizer, combined_edge_index)\n",
    "    \n",
    "test_gat(combined_edge_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINED ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.3272 acc_train: 0.8768 acc_val: 0.7474\n",
      "Epoch: 0002 loss_train: 0.3307 acc_train: 0.8787 acc_val: 0.7673\n",
      "Epoch: 0003 loss_train: 0.3300 acc_train: 0.8774 acc_val: 0.7184\n",
      "Epoch: 0004 loss_train: 0.3254 acc_train: 0.8794 acc_val: 0.7559\n",
      "Epoch: 0005 loss_train: 0.3259 acc_train: 0.8793 acc_val: 0.7634\n",
      "Epoch: 0006 loss_train: 0.3256 acc_train: 0.8790 acc_val: 0.7318\n",
      "Epoch: 0007 loss_train: 0.3251 acc_train: 0.8810 acc_val: 0.7704\n",
      "Epoch: 0008 loss_train: 0.3233 acc_train: 0.8799 acc_val: 0.7365\n",
      "Epoch: 0009 loss_train: 0.3213 acc_train: 0.8816 acc_val: 0.7533\n",
      "Epoch: 0010 loss_train: 0.3219 acc_train: 0.8807 acc_val: 0.7637\n",
      "Epoch: 0011 loss_train: 0.3236 acc_train: 0.8797 acc_val: 0.7233\n",
      "Epoch: 0012 loss_train: 0.3247 acc_train: 0.8833 acc_val: 0.7726\n",
      "Epoch: 0013 loss_train: 0.3272 acc_train: 0.8782 acc_val: 0.7162\n",
      "Epoch: 0014 loss_train: 0.3216 acc_train: 0.8823 acc_val: 0.7724\n",
      "Epoch: 0015 loss_train: 0.3186 acc_train: 0.8839 acc_val: 0.7401\n",
      "Epoch: 0016 loss_train: 0.3188 acc_train: 0.8825 acc_val: 0.7380\n",
      "Epoch: 0017 loss_train: 0.3200 acc_train: 0.8828 acc_val: 0.7753\n",
      "Epoch: 0018 loss_train: 0.3211 acc_train: 0.8809 acc_val: 0.7242\n",
      "Epoch: 0019 loss_train: 0.3183 acc_train: 0.8846 acc_val: 0.7638\n",
      "Epoch: 0020 loss_train: 0.3160 acc_train: 0.8835 acc_val: 0.7525\n",
      "Epoch: 0021 loss_train: 0.3165 acc_train: 0.8834 acc_val: 0.7471\n",
      "Epoch: 0022 loss_train: 0.3188 acc_train: 0.8856 acc_val: 0.7660\n",
      "Epoch: 0023 loss_train: 0.3210 acc_train: 0.8819 acc_val: 0.7268\n",
      "Epoch: 0024 loss_train: 0.3223 acc_train: 0.8818 acc_val: 0.7895\n",
      "Epoch: 0025 loss_train: 0.3199 acc_train: 0.8829 acc_val: 0.7242\n",
      "Epoch: 0026 loss_train: 0.3169 acc_train: 0.8856 acc_val: 0.7613\n",
      "Epoch: 0027 loss_train: 0.3133 acc_train: 0.8855 acc_val: 0.7571\n",
      "Epoch: 0028 loss_train: 0.3147 acc_train: 0.8845 acc_val: 0.7386\n",
      "Epoch: 0029 loss_train: 0.3168 acc_train: 0.8871 acc_val: 0.7735\n",
      "Epoch: 0030 loss_train: 0.3191 acc_train: 0.8832 acc_val: 0.7232\n",
      "Epoch: 0031 loss_train: 0.3180 acc_train: 0.8838 acc_val: 0.7832\n",
      "Epoch: 0032 loss_train: 0.3133 acc_train: 0.8856 acc_val: 0.7333\n",
      "Epoch: 0033 loss_train: 0.3110 acc_train: 0.8868 acc_val: 0.7550\n",
      "Epoch: 0034 loss_train: 0.3134 acc_train: 0.8857 acc_val: 0.7785\n",
      "Epoch: 0035 loss_train: 0.3221 acc_train: 0.8830 acc_val: 0.7117\n",
      "Epoch: 0036 loss_train: 0.3234 acc_train: 0.8867 acc_val: 0.7796\n",
      "Epoch: 0037 loss_train: 0.3254 acc_train: 0.8799 acc_val: 0.7328\n",
      "Epoch: 0038 loss_train: 0.3123 acc_train: 0.8838 acc_val: 0.7688\n",
      "Epoch: 0039 loss_train: 0.3227 acc_train: 0.8877 acc_val: 0.7687\n",
      "Epoch: 0040 loss_train: 0.3393 acc_train: 0.8774 acc_val: 0.6834\n",
      "Epoch: 0041 loss_train: 0.3238 acc_train: 0.8787 acc_val: 0.8043\n",
      "Epoch: 0042 loss_train: 0.3144 acc_train: 0.8851 acc_val: 0.7805\n",
      "Epoch: 0043 loss_train: 0.3302 acc_train: 0.8810 acc_val: 0.6786\n",
      "Epoch: 0044 loss_train: 0.3164 acc_train: 0.8895 acc_val: 0.7503\n",
      "Epoch: 0045 loss_train: 0.3133 acc_train: 0.8854 acc_val: 0.7807\n",
      "Epoch: 0046 loss_train: 0.3192 acc_train: 0.8811 acc_val: 0.7483\n",
      "Epoch: 0047 loss_train: 0.3078 acc_train: 0.8877 acc_val: 0.7496\n",
      "Epoch: 0048 loss_train: 0.3215 acc_train: 0.8885 acc_val: 0.7582\n",
      "Epoch: 0049 loss_train: 0.3204 acc_train: 0.8830 acc_val: 0.7095\n",
      "Epoch: 0050 loss_train: 0.3122 acc_train: 0.8836 acc_val: 0.7745\n",
      "Test set results: test_loss= 0.6468 test_accuracy= 0.7121 precision= 0.6744 recall= 0.8171 f1_score= 0.7390 auc= 0.7123\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_gat(epoch, optimizer, all_edge_index)\n",
    "    \n",
    "test_gat(all_edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
