{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gsage-model import BotGraphSAGE\n",
    "from utils import accuracy, init_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "embedding_size = 32\n",
    "dropout = 0.1\n",
    "lr = 1e-2\n",
    "weight_decay = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re calculate Des Tensor\n",
    "path = \"/Dataset/\"\n",
    "des_tensor = torch.load(path + \"filtered_des_tensor.pt\").t().to(device)\n",
    "\n",
    "num_prop = torch.load(path + \"filtered_num_properties_tensor.pt\").t().to(device)\n",
    "category_prop = torch.load(path + \"filtered_cat_properties_tensor.pt\").t().to(device)\n",
    "labels = torch.load(path + \"filtered_label.pt\").t().to(device)\n",
    "\n",
    "tweets_tensor = torch.load(\"/Users/ketanjadhav/Documents/BotRGCN/processed_data/tweets_tensor.pt\").t().to(device)\n",
    "\n",
    "train_idx = torch.load(path + \"filtered_train_idx.pt\").to(device)\n",
    "val_idx = torch.load(path + \"filtered_val_idx.pt\").to(device)\n",
    "test_idx = torch.load(path + \"filtered_test_idx.pt\").to(device)\n",
    "\n",
    "edge_index = torch.load(path + \"filtered_edge_index.pt\").to(device)\n",
    "edge_type = torch.load(path + \"filtered_edge_type.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# followers_edge_index = torch.load(\"./tensors/followers_edge_index.pt\").to(device)\n",
    "# following_edge_index = torch.load(\"./tensors/following_edge_index.pt\").to(device)\n",
    "# combined_foll_edge_index = torch.load(\"./tensors/foll_combined_edge_index.pt\").to(device)\n",
    "# combined_foll_edge_type = torch.load(\"./tensors/foll_combined_edge_type.pt\").to(device)\n",
    "# interactions_edge_index = torch.load(\"./tensors/interactions_edge_index.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BotGraphSAGE(\n",
       "  (linear_relu_num_prop): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (linear_relu_cat_prop): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (linear_relu_input): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (sage1): GraphSAGE(32, 32, num_layers=2)\n",
       "  (sage2): GraphSAGE(32, 32, num_layers=2)\n",
       "  (linear_relu_output1): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (linear_output2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sage_model=BotGraphSAGE(cat_prop_size=3,embedding_dimension=32).to(device)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(sage_model.parameters(),\n",
    "                    lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "sage_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sage(epoch, optimizer, train_edge_index):\n",
    "    sage_model.train()\n",
    "    output = sage_model(des_tensor, tweets_tensor, num_prop, category_prop, train_edge_index)\n",
    "    loss_train = loss(output[train_idx], labels[train_idx])\n",
    "    acc_train = accuracy(output[train_idx], labels[train_idx])\n",
    "    acc_val = accuracy(output[val_idx], labels[val_idx])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()))\n",
    "    \n",
    "    return acc_train, loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sage(test_edge_index):\n",
    "    sage_model.eval()\n",
    "    output = sage_model(des_tensor, tweets_tensor, num_prop, category_prop, test_edge_index)\n",
    "    loss_test = loss(output[test_idx], labels[test_idx])\n",
    "    acc_test = accuracy(output[test_idx], labels[test_idx])\n",
    "    \n",
    "    output = output.max(1)[1].to('cpu').detach().numpy()\n",
    "    label = labels.to('cpu').detach().numpy()\n",
    "    \n",
    "    f1 = f1_score(label[test_idx], output[test_idx])\n",
    "    precision = precision_score(label[test_idx], output[test_idx])\n",
    "    recall = recall_score(label[test_idx], output[test_idx])\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(label[test_idx], output[test_idx], pos_label=1)\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    \n",
    "    print(\"Test set results:\",\n",
    "          \"test_loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"test_accuracy= {:.4f}\".format(acc_test.item()),\n",
    "          \"precision= {:.4f}\".format(precision.item()),\n",
    "          \"recall= {:.4f}\".format(recall.item()),\n",
    "          \"f1_score= {:.4f}\".format(f1.item()),\n",
    "          \"auc= {:.4f}\".format(auc_val.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case we want to split edges\n",
    "\n",
    "# num_edges = followers_edge_index.size(1)\n",
    "# indices = torch.arange(num_edges)\n",
    "\n",
    "# train_indices, test_indices = train_test_split(indices.numpy(), test_size=0.2, random_state=42)\n",
    "\n",
    "# train_edge_index = followers_edge_index[:, train_indices]\n",
    "# test_edge_index = followers_edge_index[:, test_indices]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.4720 acc_train: 0.7793 acc_val: 0.5041\n",
      "Epoch: 0002 loss_train: 0.4556 acc_train: 0.7799 acc_val: 0.5057\n",
      "Epoch: 0003 loss_train: 0.4444 acc_train: 0.7748 acc_val: 0.5953\n",
      "Epoch: 0004 loss_train: 0.4360 acc_train: 0.7824 acc_val: 0.5550\n",
      "Epoch: 0005 loss_train: 0.4346 acc_train: 0.7811 acc_val: 0.3351\n",
      "Epoch: 0006 loss_train: 0.4262 acc_train: 0.7887 acc_val: 0.4035\n",
      "Epoch: 0007 loss_train: 0.4292 acc_train: 0.7805 acc_val: 0.5807\n",
      "Epoch: 0008 loss_train: 0.4257 acc_train: 0.7911 acc_val: 0.4430\n",
      "Epoch: 0009 loss_train: 0.4195 acc_train: 0.7895 acc_val: 0.4854\n",
      "Epoch: 0010 loss_train: 0.4193 acc_train: 0.7856 acc_val: 0.5636\n",
      "Epoch: 0011 loss_train: 0.4196 acc_train: 0.7897 acc_val: 0.3534\n",
      "Epoch: 0012 loss_train: 0.4111 acc_train: 0.7945 acc_val: 0.4925\n",
      "Epoch: 0013 loss_train: 0.4111 acc_train: 0.7938 acc_val: 0.6158\n",
      "Epoch: 0014 loss_train: 0.4074 acc_train: 0.7919 acc_val: 0.4737\n",
      "Epoch: 0015 loss_train: 0.4077 acc_train: 0.7919 acc_val: 0.4705\n",
      "Epoch: 0016 loss_train: 0.4040 acc_train: 0.7960 acc_val: 0.5886\n",
      "Epoch: 0017 loss_train: 0.4020 acc_train: 0.8030 acc_val: 0.6399\n",
      "Epoch: 0018 loss_train: 0.4011 acc_train: 0.7963 acc_val: 0.4233\n",
      "Epoch: 0019 loss_train: 0.3985 acc_train: 0.8027 acc_val: 0.4913\n",
      "Epoch: 0020 loss_train: 0.3980 acc_train: 0.8068 acc_val: 0.6894\n",
      "Epoch: 0021 loss_train: 0.3948 acc_train: 0.8007 acc_val: 0.5275\n",
      "Epoch: 0022 loss_train: 0.3929 acc_train: 0.8047 acc_val: 0.5695\n",
      "Epoch: 0023 loss_train: 0.3948 acc_train: 0.8104 acc_val: 0.7709\n",
      "Epoch: 0024 loss_train: 0.3942 acc_train: 0.8038 acc_val: 0.4771\n",
      "Epoch: 0025 loss_train: 0.3881 acc_train: 0.8177 acc_val: 0.7110\n",
      "Epoch: 0026 loss_train: 0.3872 acc_train: 0.8171 acc_val: 0.6987\n",
      "Epoch: 0027 loss_train: 0.3891 acc_train: 0.8073 acc_val: 0.5131\n",
      "Epoch: 0028 loss_train: 0.3865 acc_train: 0.8185 acc_val: 0.7807\n",
      "Epoch: 0029 loss_train: 0.3840 acc_train: 0.8180 acc_val: 0.6124\n",
      "Epoch: 0030 loss_train: 0.3826 acc_train: 0.8210 acc_val: 0.6973\n",
      "Epoch: 0031 loss_train: 0.3811 acc_train: 0.8231 acc_val: 0.7206\n",
      "Epoch: 0032 loss_train: 0.3811 acc_train: 0.8200 acc_val: 0.6112\n",
      "Epoch: 0033 loss_train: 0.3889 acc_train: 0.8111 acc_val: 0.8066\n",
      "Epoch: 0034 loss_train: 0.4222 acc_train: 0.7836 acc_val: 0.2959\n",
      "Epoch: 0035 loss_train: 0.3846 acc_train: 0.8188 acc_val: 0.7522\n",
      "Epoch: 0036 loss_train: 0.4025 acc_train: 0.8013 acc_val: 0.8496\n",
      "Epoch: 0037 loss_train: 0.3988 acc_train: 0.7943 acc_val: 0.3766\n",
      "Epoch: 0038 loss_train: 0.4065 acc_train: 0.7878 acc_val: 0.3352\n",
      "Epoch: 0039 loss_train: 0.3885 acc_train: 0.8107 acc_val: 0.5435\n",
      "Epoch: 0040 loss_train: 0.4022 acc_train: 0.8068 acc_val: 0.8159\n",
      "Epoch: 0041 loss_train: 0.3922 acc_train: 0.8162 acc_val: 0.7662\n",
      "Epoch: 0042 loss_train: 0.3889 acc_train: 0.8066 acc_val: 0.5180\n",
      "Epoch: 0043 loss_train: 0.3958 acc_train: 0.7991 acc_val: 0.4295\n",
      "Epoch: 0044 loss_train: 0.3871 acc_train: 0.8103 acc_val: 0.5212\n",
      "Epoch: 0045 loss_train: 0.3856 acc_train: 0.8157 acc_val: 0.7968\n",
      "Epoch: 0046 loss_train: 0.3900 acc_train: 0.8093 acc_val: 0.8230\n",
      "Epoch: 0047 loss_train: 0.3820 acc_train: 0.8214 acc_val: 0.6241\n",
      "Epoch: 0048 loss_train: 0.3879 acc_train: 0.8123 acc_val: 0.5023\n",
      "Epoch: 0049 loss_train: 0.3792 acc_train: 0.8229 acc_val: 0.7121\n",
      "Epoch: 0050 loss_train: 0.3855 acc_train: 0.8130 acc_val: 0.8170\n",
      "Test set results: test_loss= 0.6227 test_accuracy= 0.6773 precision= 0.6445 recall= 0.7874 f1_score= 0.7088 auc= 0.6776\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_sage(epoch, optimizer, edge_index)\n",
    "    \n",
    "test_sage(edge_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOLLOWING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.3771 acc_train: 0.8256 acc_val: 0.7452\n",
      "Epoch: 0002 loss_train: 0.3818 acc_train: 0.8175 acc_val: 0.5380\n",
      "Epoch: 0003 loss_train: 0.3784 acc_train: 0.8231 acc_val: 0.6144\n",
      "Epoch: 0004 loss_train: 0.3797 acc_train: 0.8216 acc_val: 0.7786\n",
      "Epoch: 0005 loss_train: 0.3773 acc_train: 0.8240 acc_val: 0.7562\n",
      "Epoch: 0006 loss_train: 0.3780 acc_train: 0.8235 acc_val: 0.6152\n",
      "Epoch: 0007 loss_train: 0.3751 acc_train: 0.8279 acc_val: 0.6558\n",
      "Epoch: 0008 loss_train: 0.3780 acc_train: 0.8213 acc_val: 0.7829\n",
      "Epoch: 0009 loss_train: 0.3733 acc_train: 0.8284 acc_val: 0.7258\n",
      "Epoch: 0010 loss_train: 0.3763 acc_train: 0.8267 acc_val: 0.6349\n",
      "Epoch: 0011 loss_train: 0.3734 acc_train: 0.8259 acc_val: 0.7446\n",
      "Epoch: 0012 loss_train: 0.3733 acc_train: 0.8250 acc_val: 0.7685\n",
      "Epoch: 0013 loss_train: 0.3735 acc_train: 0.8268 acc_val: 0.6245\n",
      "Epoch: 0014 loss_train: 0.3706 acc_train: 0.8294 acc_val: 0.7233\n",
      "Epoch: 0015 loss_train: 0.3715 acc_train: 0.8277 acc_val: 0.7480\n",
      "Epoch: 0016 loss_train: 0.3717 acc_train: 0.8290 acc_val: 0.6401\n",
      "Epoch: 0017 loss_train: 0.3696 acc_train: 0.8292 acc_val: 0.7437\n",
      "Epoch: 0018 loss_train: 0.3686 acc_train: 0.8296 acc_val: 0.7348\n",
      "Epoch: 0019 loss_train: 0.3692 acc_train: 0.8305 acc_val: 0.6692\n",
      "Epoch: 0020 loss_train: 0.3698 acc_train: 0.8267 acc_val: 0.7690\n",
      "Epoch: 0021 loss_train: 0.3691 acc_train: 0.8301 acc_val: 0.6611\n",
      "Epoch: 0022 loss_train: 0.3672 acc_train: 0.8288 acc_val: 0.7500\n",
      "Epoch: 0023 loss_train: 0.3659 acc_train: 0.8319 acc_val: 0.7114\n",
      "Epoch: 0024 loss_train: 0.3652 acc_train: 0.8324 acc_val: 0.7043\n",
      "Epoch: 0025 loss_train: 0.3667 acc_train: 0.8289 acc_val: 0.7606\n",
      "Epoch: 0026 loss_train: 0.3779 acc_train: 0.8143 acc_val: 0.4972\n",
      "Epoch: 0027 loss_train: 0.4030 acc_train: 0.8058 acc_val: 0.8522\n",
      "Epoch: 0028 loss_train: 0.4009 acc_train: 0.7955 acc_val: 0.3669\n",
      "Epoch: 0029 loss_train: 0.3861 acc_train: 0.8093 acc_val: 0.4877\n",
      "Epoch: 0030 loss_train: 0.3853 acc_train: 0.8187 acc_val: 0.7760\n",
      "Epoch: 0031 loss_train: 0.3893 acc_train: 0.8163 acc_val: 0.8200\n",
      "Epoch: 0032 loss_train: 0.3810 acc_train: 0.8191 acc_val: 0.5667\n",
      "Epoch: 0033 loss_train: 0.3894 acc_train: 0.8023 acc_val: 0.4232\n",
      "Epoch: 0034 loss_train: 0.3769 acc_train: 0.8173 acc_val: 0.5477\n",
      "Epoch: 0035 loss_train: 0.3769 acc_train: 0.8230 acc_val: 0.7842\n",
      "Epoch: 0036 loss_train: 0.3819 acc_train: 0.8198 acc_val: 0.8029\n",
      "Epoch: 0037 loss_train: 0.3761 acc_train: 0.8271 acc_val: 0.6869\n",
      "Epoch: 0038 loss_train: 0.3761 acc_train: 0.8232 acc_val: 0.5893\n",
      "Epoch: 0039 loss_train: 0.3726 acc_train: 0.8267 acc_val: 0.6865\n",
      "Epoch: 0040 loss_train: 0.3753 acc_train: 0.8230 acc_val: 0.7661\n",
      "Epoch: 0041 loss_train: 0.3692 acc_train: 0.8292 acc_val: 0.7406\n",
      "Epoch: 0042 loss_train: 0.3736 acc_train: 0.8232 acc_val: 0.6626\n",
      "Epoch: 0043 loss_train: 0.3725 acc_train: 0.8241 acc_val: 0.6841\n",
      "Epoch: 0044 loss_train: 0.3690 acc_train: 0.8266 acc_val: 0.7602\n",
      "Epoch: 0045 loss_train: 0.3702 acc_train: 0.8261 acc_val: 0.7564\n",
      "Epoch: 0046 loss_train: 0.3687 acc_train: 0.8295 acc_val: 0.6768\n",
      "Epoch: 0047 loss_train: 0.3665 acc_train: 0.8312 acc_val: 0.6856\n",
      "Epoch: 0048 loss_train: 0.3678 acc_train: 0.8282 acc_val: 0.7542\n",
      "Epoch: 0049 loss_train: 0.3664 acc_train: 0.8302 acc_val: 0.7504\n",
      "Epoch: 0050 loss_train: 0.3656 acc_train: 0.8311 acc_val: 0.6568\n",
      "Test set results: test_loss= 0.6400 test_accuracy= 0.6883 precision= 0.6695 recall= 0.7405 f1_score= 0.7032 auc= 0.6884\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "following_edge_index = torch.load(path + \"filtered_following_edge_index.pt\").to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_sage(epoch, optimizer, following_edge_index)\n",
    "    \n",
    "test_sage(following_edge_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOLLOWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.3651 acc_train: 0.8321 acc_val: 0.6820\n",
      "Epoch: 0002 loss_train: 0.3662 acc_train: 0.8286 acc_val: 0.7763\n",
      "Epoch: 0003 loss_train: 0.3643 acc_train: 0.8338 acc_val: 0.6799\n",
      "Epoch: 0004 loss_train: 0.3625 acc_train: 0.8348 acc_val: 0.6915\n",
      "Epoch: 0005 loss_train: 0.3635 acc_train: 0.8310 acc_val: 0.7740\n",
      "Epoch: 0006 loss_train: 0.3609 acc_train: 0.8344 acc_val: 0.6831\n",
      "Epoch: 0007 loss_train: 0.3605 acc_train: 0.8338 acc_val: 0.6946\n",
      "Epoch: 0008 loss_train: 0.3614 acc_train: 0.8331 acc_val: 0.7620\n",
      "Epoch: 0009 loss_train: 0.3586 acc_train: 0.8356 acc_val: 0.7005\n",
      "Epoch: 0010 loss_train: 0.3579 acc_train: 0.8370 acc_val: 0.7073\n",
      "Epoch: 0011 loss_train: 0.3599 acc_train: 0.8333 acc_val: 0.7801\n",
      "Epoch: 0012 loss_train: 0.3639 acc_train: 0.8300 acc_val: 0.5985\n",
      "Epoch: 0013 loss_train: 0.3670 acc_train: 0.8267 acc_val: 0.8231\n",
      "Epoch: 0014 loss_train: 0.3628 acc_train: 0.8325 acc_val: 0.6272\n",
      "Epoch: 0015 loss_train: 0.3571 acc_train: 0.8355 acc_val: 0.7571\n",
      "Epoch: 0016 loss_train: 0.3567 acc_train: 0.8358 acc_val: 0.7584\n",
      "Epoch: 0017 loss_train: 0.3602 acc_train: 0.8346 acc_val: 0.6386\n",
      "Epoch: 0018 loss_train: 0.3624 acc_train: 0.8314 acc_val: 0.8104\n",
      "Epoch: 0019 loss_train: 0.3611 acc_train: 0.8328 acc_val: 0.6084\n",
      "Epoch: 0020 loss_train: 0.3579 acc_train: 0.8341 acc_val: 0.7922\n",
      "Epoch: 0021 loss_train: 0.3549 acc_train: 0.8381 acc_val: 0.6786\n",
      "Epoch: 0022 loss_train: 0.3534 acc_train: 0.8382 acc_val: 0.7512\n",
      "Epoch: 0023 loss_train: 0.3525 acc_train: 0.8387 acc_val: 0.7299\n",
      "Epoch: 0024 loss_train: 0.3520 acc_train: 0.8392 acc_val: 0.7144\n",
      "Epoch: 0025 loss_train: 0.3526 acc_train: 0.8394 acc_val: 0.7670\n",
      "Epoch: 0026 loss_train: 0.3573 acc_train: 0.8356 acc_val: 0.6247\n",
      "Epoch: 0027 loss_train: 0.3806 acc_train: 0.8180 acc_val: 0.8507\n",
      "Epoch: 0028 loss_train: 0.4199 acc_train: 0.7818 acc_val: 0.2836\n",
      "Epoch: 0029 loss_train: 0.3618 acc_train: 0.8332 acc_val: 0.7812\n",
      "Epoch: 0030 loss_train: 0.3834 acc_train: 0.8200 acc_val: 0.8395\n",
      "Epoch: 0031 loss_train: 0.3702 acc_train: 0.8220 acc_val: 0.6179\n",
      "Epoch: 0032 loss_train: 0.3806 acc_train: 0.8114 acc_val: 0.4916\n",
      "Epoch: 0033 loss_train: 0.3643 acc_train: 0.8321 acc_val: 0.6895\n",
      "Epoch: 0034 loss_train: 0.3758 acc_train: 0.8182 acc_val: 0.8122\n",
      "Epoch: 0035 loss_train: 0.3666 acc_train: 0.8249 acc_val: 0.7915\n",
      "Epoch: 0036 loss_train: 0.3677 acc_train: 0.8285 acc_val: 0.6485\n",
      "Epoch: 0037 loss_train: 0.3705 acc_train: 0.8262 acc_val: 0.6239\n",
      "Epoch: 0038 loss_train: 0.3613 acc_train: 0.8308 acc_val: 0.7633\n",
      "Epoch: 0039 loss_train: 0.3674 acc_train: 0.8229 acc_val: 0.8033\n",
      "Epoch: 0040 loss_train: 0.3606 acc_train: 0.8325 acc_val: 0.7409\n",
      "Epoch: 0041 loss_train: 0.3628 acc_train: 0.8319 acc_val: 0.6317\n",
      "Epoch: 0042 loss_train: 0.3598 acc_train: 0.8351 acc_val: 0.6803\n",
      "Epoch: 0043 loss_train: 0.3614 acc_train: 0.8329 acc_val: 0.7842\n",
      "Epoch: 0044 loss_train: 0.3589 acc_train: 0.8342 acc_val: 0.7888\n",
      "Epoch: 0045 loss_train: 0.3595 acc_train: 0.8371 acc_val: 0.6663\n",
      "Epoch: 0046 loss_train: 0.3583 acc_train: 0.8376 acc_val: 0.6720\n",
      "Epoch: 0047 loss_train: 0.3579 acc_train: 0.8343 acc_val: 0.7905\n",
      "Epoch: 0048 loss_train: 0.3559 acc_train: 0.8378 acc_val: 0.7590\n",
      "Epoch: 0049 loss_train: 0.3571 acc_train: 0.8372 acc_val: 0.6620\n",
      "Epoch: 0050 loss_train: 0.3537 acc_train: 0.8385 acc_val: 0.7276\n",
      "Test set results: test_loss= 0.6667 test_accuracy= 0.6739 precision= 0.6336 recall= 0.8206 f1_score= 0.7151 auc= 0.6742\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "followers_edge_index = torch.load(path + \"filtered_followers_edge_index.pt\").to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_sage(epoch, optimizer, followers_edge_index)\n",
    "    \n",
    "test_sage(followers_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.3492 acc_train: 0.8401 acc_val: 0.6757\n",
      "Epoch: 0002 loss_train: 0.3498 acc_train: 0.8394 acc_val: 0.7778\n",
      "Epoch: 0003 loss_train: 0.3553 acc_train: 0.8345 acc_val: 0.6103\n",
      "Epoch: 0004 loss_train: 0.3610 acc_train: 0.8336 acc_val: 0.8202\n",
      "Epoch: 0005 loss_train: 0.3703 acc_train: 0.8259 acc_val: 0.5496\n",
      "Epoch: 0006 loss_train: 0.3626 acc_train: 0.8315 acc_val: 0.8093\n",
      "Epoch: 0007 loss_train: 0.3481 acc_train: 0.8402 acc_val: 0.7203\n",
      "Epoch: 0008 loss_train: 0.3573 acc_train: 0.8339 acc_val: 0.6289\n",
      "Epoch: 0009 loss_train: 0.3546 acc_train: 0.8349 acc_val: 0.8039\n",
      "Epoch: 0010 loss_train: 0.3484 acc_train: 0.8412 acc_val: 0.7180\n",
      "Epoch: 0011 loss_train: 0.3499 acc_train: 0.8399 acc_val: 0.6603\n",
      "Epoch: 0012 loss_train: 0.3573 acc_train: 0.8322 acc_val: 0.8017\n",
      "Epoch: 0013 loss_train: 0.3513 acc_train: 0.8386 acc_val: 0.6522\n",
      "Epoch: 0014 loss_train: 0.3476 acc_train: 0.8401 acc_val: 0.7428\n",
      "Epoch: 0015 loss_train: 0.3487 acc_train: 0.8393 acc_val: 0.7741\n",
      "Epoch: 0016 loss_train: 0.3503 acc_train: 0.8378 acc_val: 0.6664\n",
      "Epoch: 0017 loss_train: 0.3456 acc_train: 0.8426 acc_val: 0.7442\n",
      "Epoch: 0018 loss_train: 0.3472 acc_train: 0.8420 acc_val: 0.7742\n",
      "Epoch: 0019 loss_train: 0.3483 acc_train: 0.8408 acc_val: 0.6624\n",
      "Epoch: 0020 loss_train: 0.3474 acc_train: 0.8384 acc_val: 0.7868\n",
      "Epoch: 0021 loss_train: 0.3456 acc_train: 0.8416 acc_val: 0.7019\n",
      "Epoch: 0022 loss_train: 0.3432 acc_train: 0.8426 acc_val: 0.7401\n",
      "Epoch: 0023 loss_train: 0.3440 acc_train: 0.8418 acc_val: 0.7558\n",
      "Epoch: 0024 loss_train: 0.3430 acc_train: 0.8427 acc_val: 0.6988\n",
      "Epoch: 0025 loss_train: 0.3441 acc_train: 0.8440 acc_val: 0.7729\n",
      "Epoch: 0026 loss_train: 0.3463 acc_train: 0.8409 acc_val: 0.6690\n",
      "Epoch: 0027 loss_train: 0.3532 acc_train: 0.8339 acc_val: 0.8282\n",
      "Epoch: 0028 loss_train: 0.3800 acc_train: 0.8155 acc_val: 0.4728\n",
      "Epoch: 0029 loss_train: 0.4060 acc_train: 0.8072 acc_val: 0.8878\n",
      "Epoch: 0030 loss_train: 0.3503 acc_train: 0.8373 acc_val: 0.6843\n",
      "Epoch: 0031 loss_train: 0.3722 acc_train: 0.8202 acc_val: 0.5265\n",
      "Epoch: 0032 loss_train: 0.3580 acc_train: 0.8354 acc_val: 0.7608\n",
      "Epoch: 0033 loss_train: 0.3689 acc_train: 0.8256 acc_val: 0.8333\n",
      "Epoch: 0034 loss_train: 0.3534 acc_train: 0.8354 acc_val: 0.7756\n",
      "Epoch: 0035 loss_train: 0.3621 acc_train: 0.8323 acc_val: 0.6420\n",
      "Epoch: 0036 loss_train: 0.3552 acc_train: 0.8386 acc_val: 0.6871\n",
      "Epoch: 0037 loss_train: 0.3532 acc_train: 0.8336 acc_val: 0.8040\n",
      "Epoch: 0038 loss_train: 0.3578 acc_train: 0.8302 acc_val: 0.8142\n",
      "Epoch: 0039 loss_train: 0.3515 acc_train: 0.8399 acc_val: 0.7095\n",
      "Epoch: 0040 loss_train: 0.3534 acc_train: 0.8391 acc_val: 0.6504\n",
      "Epoch: 0041 loss_train: 0.3525 acc_train: 0.8378 acc_val: 0.7426\n",
      "Epoch: 0042 loss_train: 0.3507 acc_train: 0.8390 acc_val: 0.7810\n",
      "Epoch: 0043 loss_train: 0.3488 acc_train: 0.8405 acc_val: 0.7268\n",
      "Epoch: 0044 loss_train: 0.3521 acc_train: 0.8373 acc_val: 0.7058\n",
      "Epoch: 0045 loss_train: 0.3483 acc_train: 0.8394 acc_val: 0.7587\n",
      "Epoch: 0046 loss_train: 0.3496 acc_train: 0.8394 acc_val: 0.7557\n",
      "Epoch: 0047 loss_train: 0.3481 acc_train: 0.8403 acc_val: 0.7101\n",
      "Epoch: 0048 loss_train: 0.3459 acc_train: 0.8420 acc_val: 0.7103\n",
      "Epoch: 0049 loss_train: 0.3477 acc_train: 0.8407 acc_val: 0.7671\n",
      "Epoch: 0050 loss_train: 0.3455 acc_train: 0.8426 acc_val: 0.7549\n",
      "Test set results: test_loss= 0.6264 test_accuracy= 0.6877 precision= 0.6682 recall= 0.7423 f1_score= 0.7033 auc= 0.6878\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "interactions_edge_index = torch.load(path + \"filtered_interaction_edge_index.pt\").to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_sage(epoch, optimizer, interactions_edge_index)\n",
    "    \n",
    "test_sage(interactions_edge_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.3485 acc_train: 0.8409 acc_val: 0.6864\n",
      "Epoch: 0002 loss_train: 0.3479 acc_train: 0.8398 acc_val: 0.7637\n",
      "Epoch: 0003 loss_train: 0.3453 acc_train: 0.8421 acc_val: 0.7318\n",
      "Epoch: 0004 loss_train: 0.3459 acc_train: 0.8409 acc_val: 0.7348\n",
      "Epoch: 0005 loss_train: 0.3448 acc_train: 0.8416 acc_val: 0.7585\n",
      "Epoch: 0006 loss_train: 0.3443 acc_train: 0.8417 acc_val: 0.7144\n",
      "Epoch: 0007 loss_train: 0.3434 acc_train: 0.8427 acc_val: 0.7566\n",
      "Epoch: 0008 loss_train: 0.3431 acc_train: 0.8444 acc_val: 0.6997\n",
      "Epoch: 0009 loss_train: 0.3433 acc_train: 0.8439 acc_val: 0.7770\n",
      "Epoch: 0010 loss_train: 0.3483 acc_train: 0.8392 acc_val: 0.6440\n",
      "Epoch: 0011 loss_train: 0.3794 acc_train: 0.8190 acc_val: 0.8641\n",
      "Epoch: 0012 loss_train: 0.4409 acc_train: 0.7809 acc_val: 0.2837\n",
      "Epoch: 0013 loss_train: 0.3589 acc_train: 0.8344 acc_val: 0.7883\n",
      "Epoch: 0014 loss_train: 0.3980 acc_train: 0.8119 acc_val: 0.8721\n",
      "Epoch: 0015 loss_train: 0.3671 acc_train: 0.8308 acc_val: 0.7367\n",
      "Epoch: 0016 loss_train: 0.3810 acc_train: 0.8116 acc_val: 0.5069\n",
      "Epoch: 0017 loss_train: 0.3827 acc_train: 0.8098 acc_val: 0.4894\n",
      "Epoch: 0018 loss_train: 0.3654 acc_train: 0.8274 acc_val: 0.6715\n",
      "Epoch: 0019 loss_train: 0.3732 acc_train: 0.8224 acc_val: 0.8062\n",
      "Epoch: 0020 loss_train: 0.3745 acc_train: 0.8210 acc_val: 0.8215\n",
      "Epoch: 0021 loss_train: 0.3600 acc_train: 0.8326 acc_val: 0.7471\n",
      "Epoch: 0022 loss_train: 0.3644 acc_train: 0.8306 acc_val: 0.6182\n",
      "Epoch: 0023 loss_train: 0.3623 acc_train: 0.8335 acc_val: 0.6292\n",
      "Epoch: 0024 loss_train: 0.3557 acc_train: 0.8370 acc_val: 0.7735\n",
      "Epoch: 0025 loss_train: 0.3623 acc_train: 0.8274 acc_val: 0.8347\n",
      "Epoch: 0026 loss_train: 0.3542 acc_train: 0.8371 acc_val: 0.7780\n",
      "Epoch: 0027 loss_train: 0.3575 acc_train: 0.8351 acc_val: 0.6368\n",
      "Epoch: 0028 loss_train: 0.3562 acc_train: 0.8361 acc_val: 0.6438\n",
      "Epoch: 0029 loss_train: 0.3527 acc_train: 0.8385 acc_val: 0.7657\n",
      "Epoch: 0030 loss_train: 0.3564 acc_train: 0.8360 acc_val: 0.7972\n",
      "Epoch: 0031 loss_train: 0.3502 acc_train: 0.8411 acc_val: 0.7185\n",
      "Epoch: 0032 loss_train: 0.3545 acc_train: 0.8379 acc_val: 0.6465\n",
      "Epoch: 0033 loss_train: 0.3492 acc_train: 0.8414 acc_val: 0.7266\n",
      "Epoch: 0034 loss_train: 0.3523 acc_train: 0.8379 acc_val: 0.7957\n",
      "Epoch: 0035 loss_train: 0.3483 acc_train: 0.8409 acc_val: 0.7566\n",
      "Epoch: 0036 loss_train: 0.3504 acc_train: 0.8402 acc_val: 0.6714\n",
      "Epoch: 0037 loss_train: 0.3467 acc_train: 0.8422 acc_val: 0.7217\n",
      "Epoch: 0038 loss_train: 0.3492 acc_train: 0.8391 acc_val: 0.7953\n",
      "Epoch: 0039 loss_train: 0.3450 acc_train: 0.8427 acc_val: 0.7418\n",
      "Epoch: 0040 loss_train: 0.3475 acc_train: 0.8419 acc_val: 0.6779\n",
      "Epoch: 0041 loss_train: 0.3441 acc_train: 0.8433 acc_val: 0.7546\n",
      "Epoch: 0042 loss_train: 0.3454 acc_train: 0.8421 acc_val: 0.7798\n",
      "Epoch: 0043 loss_train: 0.3441 acc_train: 0.8432 acc_val: 0.6976\n",
      "Epoch: 0044 loss_train: 0.3425 acc_train: 0.8439 acc_val: 0.7168\n",
      "Epoch: 0045 loss_train: 0.3440 acc_train: 0.8431 acc_val: 0.7869\n",
      "Epoch: 0046 loss_train: 0.3414 acc_train: 0.8443 acc_val: 0.7073\n",
      "Epoch: 0047 loss_train: 0.3404 acc_train: 0.8455 acc_val: 0.7159\n",
      "Epoch: 0048 loss_train: 0.3421 acc_train: 0.8441 acc_val: 0.7910\n",
      "Epoch: 0049 loss_train: 0.3424 acc_train: 0.8429 acc_val: 0.6771\n",
      "Epoch: 0050 loss_train: 0.3407 acc_train: 0.8450 acc_val: 0.7839\n",
      "Test set results: test_loss= 0.6391 test_accuracy= 0.6884 precision= 0.6640 recall= 0.7598 f1_score= 0.7087 auc= 0.6886\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "all_edge_index = torch.load(path + \"all_combined_edge_index.pt\").to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_sage(epoch, optimizer, all_edge_index)\n",
    "    \n",
    "test_sage(all_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
